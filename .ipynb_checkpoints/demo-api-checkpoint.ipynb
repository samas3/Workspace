{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7437faa-76de-40b8-a46e-23367f6cc652",
   "metadata": {},
   "source": [
    "# 欢迎大家来到未来科技营\n",
    "本文档主要以刚刚发布的阿里云Omni模型的为例，展示如何通过调用API接口进行语音交互。\n",
    "\n",
    "之前我们已经学习了如何通过调用simpleaudio来让我们的机器人进行录音和播放音频文件，接下来我们来模拟一次跟机器人的对话场景。首先，我们按照之前的方式，录音一句与机器人的对话音频，并保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a911ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import alsaaudio\n",
    "import sounddevice as sd\n",
    "import simpleaudio as sa\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "dev = next((d for d in sd.query_devices() if d['max_output_channels'] > 0 and 'usb' in d['name'].lower()), None)\n",
    "if dev: os.environ['ALSA_CARD'] = str(dev['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d2f8b",
   "metadata": {},
   "source": [
    "## 配置API_KEY\n",
    "\n",
    "之后我们开始调用阿里大模型API，将音频文件转为对应的文字。\n",
    "\n",
    "第一步我们需要配置环境变量，以便API可以通过Key进行调用。这里我们已经为大家准备了API_KEY，配额有限，请谨慎使用。\n",
    "\n",
    "建议自行申请免费额度 https://bailian.console.aliyun.com/?tab=model#/api-key\n",
    "参考 https://bailian.console.aliyun.com/?tab=api#/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca899413",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DASHSCOPE_API_KEY'] = \"sk-da685c1884eb4d1b8b3e5320cc7324d4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c798e6-9a15-4ea0-a04f-e2f9ccb11f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 开始录音\n",
      "* 录音结束\n",
      "0.5538832\n",
      "音频已保存为 demo1.wav\n"
     ]
    }
   ],
   "source": [
    "# 录音\n",
    "fs = 44100  # 采样频率\n",
    "seconds = 5  # 录音时长，单位：秒\n",
    "output_filename = \"demo1.wav\"\n",
    "\n",
    "print(\"* 开始录音\")\n",
    "# 录制音频\n",
    "myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=1)\n",
    "sd.wait()  # 等待录音完成\n",
    "print(\"* 录音结束\")\n",
    "print(np.mean(np.abs(myrecording)))\n",
    "\n",
    "# 将浮点格式转换为整数格式\n",
    "myrecording = np.int16(myrecording / np.max(np.abs(myrecording[20000:])) * 32767)\n",
    "\n",
    "# 保存音频文件\n",
    "write(output_filename, fs, myrecording)\n",
    "print(f\"音频已保存为 {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e63361-1db3-4435-8e80-2e5d91cd830b",
   "metadata": {},
   "source": [
    "接下来我们调用接口，这里我们使用的是阿里的ASR模型进行音频转文字的解析。\n",
    "\n",
    "更多demo可参考 [官方ASR文档](https://help.aliyun.com/zh/model-studio/user-guide/automatic-speech-recognition?spm=a2c4g.11186623.help-menu-2400256.d_0_4_0.2d2f13f0a8n9c7&scm=20140722.H_2842554._.OR_help-T_cn~zh-V_1#bfee22ad38uyi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d339cdfc-a1f4-44d9-80f5-1c4ad23d7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status_code\": 200, \"request_id\": \"90f53790-19b3-983a-9694-7889e0fef70e\", \"code\": \"\", \"message\": \"\", \"output\": {\"text\": null, \"finish_reason\": null, \"choices\": [{\"finish_reason\": \"stop\", \"message\": {\"role\": \"assistant\", \"content\": [{\"text\": \"这不应该我就是用的是你的那个示例程序我一开始运行的时候\"}]}}]}, \"usage\": {\"input_tokens\": 157, \"output_tokens\": 18, \"audio_tokens\": 129}}\n"
     ]
    }
   ],
   "source": [
    "from dashscope import MultiModalConversation\n",
    "\n",
    "audio_file_path = \"demo1.wav\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"audio\": audio_file_path}],\n",
    "    }\n",
    "]\n",
    "\n",
    "response = MultiModalConversation.call(model=\"qwen-audio-asr-latest\", messages=messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04e8205-8f0b-4bf2-b18d-0cc24ec08f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这不应该我就是用的是你的那个示例程序我一开始运行的时候\n"
     ]
    }
   ],
   "source": [
    "print(response[\"output\"][\"choices\"][0][\"message\"][\"content\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be797e-dc81-42cc-9c9f-8c11db702339",
   "metadata": {},
   "source": [
    "大家可以看到调用结果返回的是一个Json格式的字典，我们获取其中的text部分为调用结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0985bca5-96d1-42ef-8fbf-93115207b9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好请介绍一下你自己\n"
     ]
    }
   ],
   "source": [
    "input_text = response[\"output\"][\"choices\"][0][\"message\"][\"content\"][0][\"text\"]\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7caa30-d666-477e-b789-e41bb59dcac2",
   "metadata": {},
   "source": [
    "## 调用API回答我们的问题\n",
    "\n",
    "接下来我们调用阿里千问模型对我们的问题进行回答。千问模型可以通过文字和语音两种方式同时对我们的问题进行回答。这里我们调用的是qwen-omni-turbo模型，选择输出模式为语音+文字。\n",
    "\n",
    "更多多模态调用方式可参考 [官方多模态文档](https://help.aliyun.com/zh/model-studio/user-guide/multimodal/?spm=a2c4g.11186623.help-menu-2400256.d_0_2.5cb12bdb5gTOut&scm=20140722.H_2878475._.OR_help-T_cn~zh-V_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a96eb1d3-0259-44c2-8370-9407e0ddc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-omni-turbo\",\n",
    "    # model=\"qwen2.5-omni-7b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": input_text}],\n",
    "    # 设置输出数据的模态，当前支持两种：[\"text\",\"audio\"]、[\"text\"]\n",
    "    modalities=[\"text\", \"audio\"],\n",
    "    audio={\"voice\": \"Cherry\", \"format\": \"wav\"},\n",
    "    # stream 必须设置为 True，否则会报错\n",
    "    stream=True,\n",
    "    stream_options={\"include_usage\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cba3e80e-7ced-4ec7-b174-a6256a29be31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嗨\n",
      "，\n",
      "我是\n",
      "阿里\n",
      "云\n",
      "研发\n",
      "的大\n",
      "规模\n",
      "语言\n",
      "模型\n",
      "通\n",
      "义\n",
      "千\n",
      "问\n",
      "。\n",
      "我可以\n",
      "陪你\n",
      "聊天\n",
      "，\n",
      "帮你\n",
      "解决问题\n",
      "，\n",
      "你\n",
      "有什么\n",
      "想\n",
      "聊\n",
      "的\n",
      "吗\n",
      "？\n",
      "\n",
      "\n",
      "CompletionUsage(completion_tokens=247, prompt_tokens=52, total_tokens=299, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=217, reasoning_tokens=None, rejected_prediction_tokens=None, text_tokens=30), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=None, text_tokens=52))\n"
     ]
    }
   ],
   "source": [
    "audio_string = \"\"\n",
    "for chunk in completion:\n",
    "    if chunk.choices:\n",
    "        if hasattr(chunk.choices[0].delta, \"audio\"):\n",
    "            try:\n",
    "                audio_string += chunk.choices[0].delta.audio[\"data\"]\n",
    "            except Exception as e:\n",
    "                print(chunk.choices[0].delta.audio[\"transcript\"])\n",
    "    else:\n",
    "        print(chunk.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4754fb6-ac20-43ff-8f99-bee3879737e1",
   "metadata": {},
   "source": [
    "我们可以看到，调用返回的结果中包含了千问的回答和其他信息，例如本次调用一共消耗了多少tokens（可以理解为费用或者算力）。\n",
    "\n",
    "返回中的文字部分我们已经打印出来了，接下来我们看下返回的音频部分。首先我们将音频解码，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11b15797-0cf2-4a0f-a2ad-5618a91628e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_bytes = base64.b64decode(audio_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61c5767-569e-4730-81df-9cf332921ab4",
   "metadata": {},
   "source": [
    "解码后我们就可以使用矩阵的形式来表达这段音频了。这里需要注意，我们的机器人它拥有两个声道，所以是一个2维的矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9edc1e96-0f81-4740-9d93-d53f154a3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_np = np.frombuffer(wav_bytes, dtype=np.int16)\n",
    "audio_np = audio_np.reshape(-1, 1)  # explicitly set as mono channel\n",
    "audio_stereo = np.repeat(audio_np, 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f65919c9-46c9-4851-96be-2058479b0b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (216960, 2)\n"
     ]
    }
   ],
   "source": [
    "print('shape: ', audio_stereo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3746141c-62c0-433b-a1d3-fd48d8fbc885",
   "metadata": {},
   "source": [
    "最后我们把音频播放出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b943206b-1860-46a2-8a22-ffa5843d2ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置音量\n",
    "m = alsaaudio.Mixer('PCM')\n",
    "m.setvolume(100)\n",
    "\n",
    "# 播放测试音频\n",
    "sd.play(audio_stereo, samplerate=24000)\n",
    "sd.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926221f9-0e79-42f3-ad62-08e8e8769d78",
   "metadata": {},
   "source": [
    "到此我们就完成了与阿里千问大模型的一轮对话啦。更多可能性期待你们自己的探索！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca58927-a96d-43c0-ae49-6c1a74a7350c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
